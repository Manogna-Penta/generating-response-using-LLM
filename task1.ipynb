{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "58f52782fd2247e58e69b5d08f4ad75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4c55ecf59fc1468cab8840fc428a0219",
              "IPY_MODEL_2df2c7afb7904290b65883b30a1aed41",
              "IPY_MODEL_d6b40192d6de4bac91656775d68f2d8b"
            ],
            "layout": "IPY_MODEL_339161f145dd4999896f7b7e6fa8d73d"
          }
        },
        "4c55ecf59fc1468cab8840fc428a0219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22c2762644e94c6497981222ee0383f7",
            "placeholder": "​",
            "style": "IPY_MODEL_49b30c9f56594d42968e675360de2a6c",
            "value": "Batches: 100%"
          }
        },
        "2df2c7afb7904290b65883b30a1aed41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65dfda5a47f4436c80804c5c61148f92",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_577e045284c64fcd99b87d5e62510d5f",
            "value": 1
          }
        },
        "d6b40192d6de4bac91656775d68f2d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dde3eb83bf0b4636b27ddf1c203df76a",
            "placeholder": "​",
            "style": "IPY_MODEL_b0e220c38b73494d99deb2f725745586",
            "value": " 1/1 [00:00&lt;00:00, 14.18it/s]"
          }
        },
        "339161f145dd4999896f7b7e6fa8d73d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22c2762644e94c6497981222ee0383f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49b30c9f56594d42968e675360de2a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "65dfda5a47f4436c80804c5c61148f92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "577e045284c64fcd99b87d5e62510d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dde3eb83bf0b4636b27ddf1c203df76a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e220c38b73494d99deb2f725745586": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Install necessary libraries**\n"
      ],
      "metadata": {
        "id": "heY9_SXKBCPp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSGDc0jeW7Zd",
        "outputId": "740d3fbb-9534-4d61-fb2d-96f999d08605"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.9.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2, faiss-cpu\n",
            "Successfully installed PyPDF2-3.0.1 faiss-cpu-1.9.0.post1\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install PyPDF2 sentence-transformers faiss-cpu openai nltk\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**upload the pdf file**"
      ],
      "metadata": {
        "id": "KYIZXbNOBOyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "kYiJPdfOZKQb",
        "outputId": "5d561a04-d6b5-487b-b5ab-755f472ca156"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8c9dcf06-f235-4b3a-a4e9-66e8a78eae1a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8c9dcf06-f235-4b3a-a4e9-66e8a78eae1a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving task1_pdf.pdf to task1_pdf.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0p7-M-KEAS0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /root/nltk_data  # Remove existing NLTK data folder\n"
      ],
      "metadata": {
        "id": "ubhAz5lkdGA3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt', force=True)\n",
        "nltk.data.path.append('/root/nltk_data')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0M5f8IxdaBk",
        "outputId": "8a8256d1-e923-4e37-db13-bf07a622b080"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdfplumber\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jdOSl5QW1_BA",
        "outputId": "360f8025-7fba-4b0d-e25c-3a4274d57994"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.10/dist-packages (0.11.4)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (11.0.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.10/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**find the tables in the pdf**"
      ],
      "metadata": {
        "id": "mv6jJrz3BY7-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "pdf_path = \"/content/task1_pdf.pdf\"\n",
        "\n",
        "# Extract tables from the PDF\n",
        "def extract_tables_from_pdf(pdf_path):\n",
        "    all_tables = []\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_number, page in enumerate(pdf.pages):\n",
        "            tables = page.extract_tables()\n",
        "            for table in tables:\n",
        "                df = pd.DataFrame(table[1:], columns=table[0])\n",
        "                df['Page'] = page_number + 1\n",
        "                all_tables.append(df)\n",
        "    return all_tables\n",
        "\n",
        "\n",
        "tables = extract_tables_from_pdf(pdf_path)\n",
        "print(f\"Total tables extracted: {len(tables)}\")\n",
        "\n",
        "\n",
        "if tables:\n",
        "    print(\"\\nFirst Table Extracted:\")\n",
        "    print(tables[0])  # Print the first table\n",
        "else:\n",
        "    print(\"No tables found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Xe9EJ4ryce5",
        "outputId": "2500e0d9-fd46-4188-f1bb-8e957aa86a7c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total tables extracted: 2\n",
            "\n",
            "First Table Extracted:\n",
            "                                                Year      2010      2011  \\\n",
            "0                                     All Industries  26093515  27535971   \n",
            "1                                      Manufacturing   4992521   5581942   \n",
            "2  Finance,\\nInsurance, Real\\nEstate, Rental,\\nLe...   4522451   4618678   \n",
            "3  Arts,\\nEntertainment,\\nRecreation,\\nAccommodat...    964032   1015238   \n",
            "4                                              Other  15614511  16320113   \n",
            "\n",
            "       2012      2013      2014      2015  Page  \n",
            "0  28663246  29601191  30895407  31397023     6  \n",
            "1   5841608   5953299   6047477   5829554     6  \n",
            "2   4797313   5031881   5339678   5597018     6  \n",
            "3   1076249   1120496   1189646   1283813     6  \n",
            "4  16948076  17495515  18318606  18686638     6  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**answering the some table related queries**"
      ],
      "metadata": {
        "id": "H7hlR8_lBrbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "queries = [\n",
        "    {\"keyword\": \"Manufacturing\", \"year\": \"2013\"},\n",
        "    {\"keyword\": \"Finance\", \"year\": \"2014\"},\n",
        "    {\"keyword\": \"Arts\", \"year\": \"2015\"}\n",
        "]\n",
        "\n",
        "\n",
        "def query_gdp(dataframe, keyword, year):\n",
        "    result = dataframe[dataframe['Year'].str.contains(keyword, case=False, na=False)]\n",
        "    if not result.empty and year in dataframe.columns:\n",
        "        return result[year].values[0]\n",
        "    return \"Data not found\"\n",
        "\n",
        "for query in queries:\n",
        "    result = query_gdp(tables[0], query[\"keyword\"], query[\"year\"])\n",
        "    print(f\"GDP for {query['keyword']} in {query['year']}: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16QLLFSNx-ks",
        "outputId": "e73500f1-605e-403a-a96e-130acfd0311e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GDP for Manufacturing in 2013: 5953299\n",
            "GDP for Finance in 2014: 5339678\n",
            "GDP for Arts in 2015: 1283813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**extract both tables and text in pdf and divide the text into some nuber of chunks**"
      ],
      "metadata": {
        "id": "6fzr_1IFCHrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def extract_text_and_tables(pdf_path):\n",
        "    all_content = []\n",
        "\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "        for page_number, page in enumerate(pdf.pages):\n",
        "\n",
        "            text = page.extract_text()\n",
        "            if text:\n",
        "                all_content.append((f\"Page {page_number+1} Text\", text))\n",
        "\n",
        "\n",
        "            tables = page.extract_tables()\n",
        "            for table in tables:\n",
        "                df = pd.DataFrame(table[1:], columns=table[0])\n",
        "                table_text = df.to_string(index=False)  # Convert table to text\n",
        "                all_content.append((f\"Page {page_number+1} Table\", table_text))\n",
        "\n",
        "    return all_content\n",
        "\n",
        "# Path to PDF\n",
        "pdf_path = \"/content/task1_pdf.pdf\"\n",
        "\n",
        "# Extract and combine content\n",
        "content_chunks = extract_text_and_tables(pdf_path)\n",
        "\n",
        "# Print the number of chunks\n",
        "print(f\"Total Chunks (Text + Tables): {len(content_chunks)}\")\n",
        "print(\"\\nFirst Chunk:\")\n",
        "print(content_chunks[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1mXwwcgyB6x",
        "outputId": "3dc66cf0-ec38-42e5-defb-9f76d8a5af50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Chunks (Text + Tables): 20\n",
            "\n",
            "First Chunk:\n",
            "('Page 1 Text', 'Tables, Charts, and\\nGraphs\\nwith Examples from History, Economics,\\nEducation, Psychology, Urban Affairs and\\nEveryday Life\\nREVISED: MICHAEL LOLKUS 2018')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "generate the word embenddings and store them in FAISS(which will act as a database to store the word embenddings)"
      ],
      "metadata": {
        "id": "Bg6-cYnnChdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "chunk_texts = [chunk[1] for chunk in content_chunks]\n",
        "embeddings = model.encode(chunk_texts, show_progress_bar=True)\n",
        "\n",
        "\n",
        "embedding_dim = embeddings[0].shape[0]\n",
        "index = faiss.IndexFlatL2(embedding_dim)\n",
        "\n",
        "\n",
        "embeddings_array = np.array(embeddings).astype('float32')\n",
        "index.add(embeddings_array)\n",
        "\n",
        "print(f\"Total Embeddings Added to FAISS Index: {index.ntotal}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "58f52782fd2247e58e69b5d08f4ad75e",
            "4c55ecf59fc1468cab8840fc428a0219",
            "2df2c7afb7904290b65883b30a1aed41",
            "d6b40192d6de4bac91656775d68f2d8b",
            "339161f145dd4999896f7b7e6fa8d73d",
            "22c2762644e94c6497981222ee0383f7",
            "49b30c9f56594d42968e675360de2a6c",
            "65dfda5a47f4436c80804c5c61148f92",
            "577e045284c64fcd99b87d5e62510d5f",
            "dde3eb83bf0b4636b27ddf1c203df76a",
            "b0e220c38b73494d99deb2f725745586"
          ]
        },
        "id": "z5X1OeH64Bi9",
        "outputId": "0631d138-c2f3-408c-a021-6850255eccc7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "58f52782fd2247e58e69b5d08f4ad75e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Embeddings Added to FAISS Index: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Search FAISS for text-based answers**"
      ],
      "metadata": {
        "id": "fJd0oAwJDBI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Search FAISS for text-based answers\n",
        "def semantic_search(query, model, index, content_chunks, top_k=3):\n",
        "    query_embedding = model.encode([query])\n",
        "    distances, indices = index.search(np.array(query_embedding).astype('float32'), top_k)\n",
        "    results = [content_chunks[i] for i in indices[0]]\n",
        "    return results\n",
        "\n",
        "\n",
        "def query_table(tables, keyword, year):\n",
        "    results = []\n",
        "    for table in tables:\n",
        "        for col in table.columns:\n",
        "            if year in col:\n",
        "                matching_rows = table[table.iloc[:, 0].str.contains(keyword, case=False, na=False)]\n",
        "                for _, row in matching_rows.iterrows():\n",
        "                    results.append((keyword, year, row[col]))\n",
        "    return results\n",
        "\n",
        "#querry\n",
        "user_query = \"What is the GDP for Manufacturing in 2013?\"\n",
        "\n",
        "# Search chunks\n",
        "semantic_results = semantic_search(user_query, model, index, content_chunks, top_k=2)\n",
        "print(\"\\nTop Semantic Search Results:\")\n",
        "for result in semantic_results:\n",
        "    print(f\"{result[0]}: {result[1]}\")\n",
        "\n",
        "#results\n",
        "table_results = query_table([tables[0]], \"Manufacturing\", \"2013\")\n",
        "print(\"\\nTable Search Results:\")\n",
        "for result in table_results:\n",
        "    print(f\"GDP for {result[0]} in {result[1]}: {result[2]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rA2jMlY4I1V",
        "outputId": "e17d7e7a-877b-417e-9fc0-e6d7aa289b69"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top Semantic Search Results:\n",
            "Page 7 Text: • The chart below is called a pie chart. It shows what\n",
            "percent “of the pie” a particular category occupies\n",
            "out of the whole.\n",
            "• If total GDP in 2015 is the entire pie, then\n",
            "manufacturing makes up 19% of that pie and finance\n",
            "makes up 18%. Notice that visually speaking, since 19%\n",
            "and 18% are so close to each other in value, their\n",
            "respective slices of the pie are similarly sized.\n",
            "2015 U.S. GDP (in millions of dollars)\n",
            "Manufacturing\n",
            "19%\n",
            "Finance, insurance, real\n",
            "estate, rental, and\n",
            "leasing\n",
            "18% Arts, entertainment,\n",
            "59%\n",
            "recreation,\n",
            "accommodation, and\n",
            "food services\n",
            "Other\n",
            "4%\n",
            "Page 6 Text: Table of Yearly U.S. GDP by\n",
            "Industry (in millions of dollars)\n",
            "Source: U.S. Bureau of Labor Statistics\n",
            "Year 2010 2011 2012 2013 2014 2015\n",
            "All Industries 26093515 27535971 28663246 29601191 30895407 31397023\n",
            "Manufacturing 4992521 5581942 5841608 5953299 6047477 5829554\n",
            "Finance,\n",
            "Insurance, Real\n",
            "4522451 4618678 4797313 5031881 5339678 5597018\n",
            "Estate, Rental,\n",
            "Leasing\n",
            "Arts,\n",
            "Entertainment,\n",
            "Recreation, 964032 1015238 1076249 1120496 1189646 1283813\n",
            "Accommodation,\n",
            "and Food Service\n",
            "Other 15614511 16320113 16948076 17495515 18318606 18686638\n",
            "\n",
            "Table Search Results:\n",
            "GDP for Manufacturing in 2013: 5953299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**now generating the response by using the LLM / transformer**"
      ],
      "metadata": {
        "id": "JxZgPB6ADT-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "#using google/flan-t5-base model to generate the text\n",
        "llm_pipeline = pipeline(\"text-generation\", model=\"google/flan-t5-base\", max_length=200)\n",
        "\n",
        "print(\"LLM pipeline loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfKo6odb4OUS",
        "outputId": "1b21fb2e-5cca-45ae-9a19-2b0e98eb2272"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n",
            "The model 'T5ForConditionalGeneration' is not supported for text-generation. Supported models are ['BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'ElectraForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM pipeline loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**generating the response for query prompt**"
      ],
      "metadata": {
        "id": "t2syL11fD57d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_llm_input(query, semantic_results, table_results):\n",
        "    \"\"\"\n",
        "    Combine retrieved semantic chunks and table search results into a single input prompt for the LLM.\n",
        "    Filter the results to prioritize chunks that contain year-based data (e.g., 2013).\n",
        "    \"\"\"\n",
        "    # Filter semantic results and table results for relevance\n",
        "    relevant_semantic_results = [result for result in semantic_results if \"2013\" in result[1]]\n",
        "    relevant_table_results = [result for result in table_results if \"2013\" in result[1]]\n",
        "\n",
        "\n",
        "    prompt = f\"Question: '{query}'\\n\\n\"\n",
        "\n",
        "\n",
        "    prompt += \"Context from Retrieved Information (Filtered for relevance):\\n\"\n",
        "    for i, (source, text) in enumerate(relevant_semantic_results, 1):\n",
        "        prompt += f\"{i}. {source}: {text.strip()}\\n\"\n",
        "\n",
        "\n",
        "    prompt += \"\\nAdditional Data from Tables (Filtered for 2013):\\n\"\n",
        "    for result in relevant_table_results:\n",
        "        keyword, year, value = result\n",
        "        prompt += f\"- The GDP for {keyword} in {year} is {value}.\\n\"\n",
        "\n",
        "\n",
        "    prompt += \"\\nAnswer the question concisely using only the necessary information provided above.\"\n",
        "\n",
        "    return prompt\n",
        "\n",
        "# query\n",
        "query = \"What is the GDP for Manufacturing in 2013?\"\n",
        "\n",
        "semantic_results = [\n",
        "    (\"Page 7 Text\", \"The chart below shows the GDP for Manufacturing, Finance, etc., including 2015 data.\"),\n",
        "    (\"Page 6 Text\", \"Table of Yearly U.S. GDP by Industry (in millions of dollars) with data from 2010 to 2015.\")\n",
        "]\n",
        "\n",
        "table_results = [\n",
        "    (\"Manufacturing\", \"2013\", \"5953299\"),\n",
        "    (\"Finance\", \"2013\", \"5031881\"),\n",
        "    (\"Arts\", \"2013\", \"1120496\")\n",
        "]\n",
        "\n",
        "\n",
        "llm_input = prepare_llm_input(query, semantic_results, table_results)\n",
        "\n",
        "\n",
        "print(\"Generated Input for LLM:\")\n",
        "print(llm_input)\n",
        "\n",
        "# Generate the final answer using the LLM\n",
        "llm_output = llm_pipeline(llm_input, truncation=True)[0][\"generated_text\"]\n",
        "\n",
        "# Display the final answer\n",
        "print(\"\\nFinal Answer Generated by the LLM:\")\n",
        "print(llm_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HdTX7eJ5N-S",
        "outputId": "a580cac0-9edf-4c78-ff8f-ce85144c49bd"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Input for LLM:\n",
            "Question: 'What is the GDP for Manufacturing in 2013?'\n",
            "\n",
            "Context from Retrieved Information (Filtered for relevance):\n",
            "\n",
            "Additional Data from Tables (Filtered for 2013):\n",
            "- The GDP for Manufacturing in 2013 is 5953299.\n",
            "- The GDP for Finance in 2013 is 5031881.\n",
            "- The GDP for Arts in 2013 is 1120496.\n",
            "\n",
            "Answer the question concisely using only the necessary information provided above.\n",
            "\n",
            "Final Answer Generated by the LLM:\n",
            "Question: 'What is the GDP for Manufacturing in 2013?'\n",
            "\n",
            "Context from Retrieved Information (Filtered for relevance):\n",
            "\n",
            "Additional Data from Tables (Filtered for 2013):\n",
            "- The GDP for Manufacturing in 2013 is 5953299.\n",
            "- The GDP for Finance in 2013 is 5031881.\n",
            "- The GDP for Arts in 2013 is 1120496.\n",
            "\n",
            "Answer the question concisely using only the necessary information provided above.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_MeiGTxN-uWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YH59fZCd5Vk-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}